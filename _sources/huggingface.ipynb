{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the FIM-MJP Model \n",
    "\n",
    "## Input to the model\n",
    "\n",
    "The model takes as an input dictionary containing at least three items and one additional argument. The input dictionary should contain the following items:\n",
    "\n",
    "   1. The _observation grid_ with size `[num_paths, grid_size]` which are the locations in time when a observation was recorded. The key in the dictionary is `observation_grid` and the data type is `float`.\n",
    "   2. The _observation values_ with size `[num_paths, grid_size]` are the actually observed values (state) of the process. The key in the dictionary is `observation_values` and the data type is `int`.\n",
    "   3. The _sequence length_ with size `[num_paths]` which is the length of the observed sequence. The key in the dictionary is `seq_length` and the data type is `int`.\n",
    "   4. The _dimension of the process_ which is an `integer` between 2 and 6. The maximum number of states that are supported by our model is 6. The argument name is `n_states`.\n",
    "\n",
    "Optionally, the dictionary can contain the following items:\n",
    "\n",
    "   - The _time normalization factor_ with size `[num_paths]` which is the factor by which the time is normalized. The key in the dictionary is `time_normalization_factors` and the data type is `float`. In case this item is not provided, the model will normalize the time by the maximum time in the observation grid.\n",
    "   - Items for calculating the loss:\n",
    "      - _intensity matrix_ with size `[num_paths, n_states, n_states]` which is the intensity matrix of the process. The key in the dictionary is `intensity_matrices` and the data type is `float`.\n",
    "      - _initial distribution_ with size `[num_paths, n_states]` which is the initial distribution of the process. The key in the dictionary is `initial_distributions` and the data type is `int`.\n",
    "      - _adjacency matrix_ with size `[num_paths, n_states, n_states]` which is the adjacency matrix of the process. The key in the dictionary is `adjacency_matrices` and the data type is `int`.\n",
    "\n",
    "### Output of the model\n",
    "\n",
    "The model returns a dictionary containing the following items:\n",
    "\n",
    "   - The _intensity matrix_ with size `[num_paths, n_states, n_states]` which is the intensity matrix of the process. The key in the dictionary is `intensity_matrices` and the data type is `float`.\n",
    "   - The _initial distribution_ with size `[num_paths, n_states]` which is the initial distribution of the process. The key in the dictionary is `initial_distributions` and the data type is `int`.\n",
    "   - The _adjacency matrix_ with size `[num_paths, n_states, n_states]` which is the adjacency matrix of the process. The key in the dictionary is `adjacency_matrices` and the data type is `int`.\n",
    "   - The _losses_ which is the loss of the model. The key in the dictionary is `loss` and the data type is `float`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from fim.trainers.utils import get_accel_type\n",
    "import pandas as pd\n",
    "\n",
    "device = get_accel_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We also provide a synthetic dataset for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104d97d4699b48a48e7a09186c022b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mjp.py:   0%|          | 0.00/7.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b523f67a17489bada0a7b6b54ebc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6_st_DFR_V=1.zip:   0%|          | 0.00/253k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffba0db717c43c6ae20d5d6ce341574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the Discrete Flashing Ratchet (DFR) dataset from Huggingface\n",
    "data = load_dataset(\"FIM4Science/mjp\", download_mode=\"force_redownload\", trust_remote_code=True, name=\"DFR_V=1\")\n",
    "data.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIMMJP(\n",
       "  (gaussian_nll): GaussianNLLLoss()\n",
       "  (init_cross_entropy): CrossEntropyLoss()\n",
       "  (pos_encodings): DeltaTimeEncoding()\n",
       "  (ts_encoder): RNNEncoder(\n",
       "    (rnn): LSTM(8, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (path_attention): MultiHeadLearnableQueryAttention(\n",
       "    (W_k): Linear(in_features=512, out_features=128, bias=False)\n",
       "    (W_v): Linear(in_features=512, out_features=128, bias=False)\n",
       "  )\n",
       "  (intensity_matrix_decoder): MLP(\n",
       "    (layers): Sequential(\n",
       "      (linear_0): Linear(in_features=2049, out_features=128, bias=True)\n",
       "      (activation_0): SELU()\n",
       "      (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation_1): SELU()\n",
       "      (output): Linear(in_features=128, out_features=60, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (initial_distribution_decoder): MLP(\n",
       "    (layers): Sequential(\n",
       "      (linear_0): Linear(in_features=2049, out_features=128, bias=True)\n",
       "      (activation_0): SELU()\n",
       "      (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation_1): SELU()\n",
       "      (output): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the FIMMJP model from Huggingface\n",
    "fimmjp = AutoModel.from_pretrained(\"FIM4Science/fim-mjp\", trust_remote_code=True)\n",
    "\n",
    "fimmjp = fimmjp.to(device)\n",
    "fimmjp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data to device\n",
    "batch = {k: v.to(device) for k, v in data[\"train\"][:1].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a batch\n",
    "n_paths_eval = [1, 30, 100, 300, 500, 1000, 5000]\n",
    "total_n_paths = batch[\"observation_grid\"].shape[1]\n",
    "statistics = total_n_paths // 300 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = defaultdict(list)\n",
    "intensity_matrices=[]\n",
    "with torch.no_grad():\n",
    "    for n_paths in n_paths_eval:\n",
    "        for _ in range(statistics):\n",
    "            paths_idx = torch.randperm(total_n_paths)[:n_paths]\n",
    "            mini_batch = batch.copy()\n",
    "            mini_batch[\"observation_grid\"] = batch[\"observation_grid\"][:, paths_idx]\n",
    "            mini_batch[\"observation_values\"] = batch[\"observation_values\"][:, paths_idx]\n",
    "            mini_batch[\"seq_lengths\"] = batch[\"seq_lengths\"][:, paths_idx]\n",
    "            output = fimmjp(mini_batch, n_states=6)\n",
    "            intensity_matrices.append(output[\"intensity_matrices\"])\n",
    "            result[n_paths].append(output[\"losses\"][\"rmse_loss\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8726817 ,  0.51337844,  0.34576902,  0.79274243,  0.10118372,\n",
       "         0.11960831],\n",
       "       [ 1.3319315 , -3.0184882 ,  0.6533575 ,  0.14318156,  0.756899  ,\n",
       "         0.13311861],\n",
       "       [ 2.1708746 ,  1.3002527 , -4.6813445 ,  0.28341696,  0.217854  ,\n",
       "         0.7089467 ],\n",
       "       [ 0.7624738 ,  0.13706328,  0.15247008, -2.6725833 ,  0.8516975 ,\n",
       "         0.76887864],\n",
       "       [ 0.1258811 ,  0.7281811 ,  0.12992634,  0.7655206 , -2.5777812 ,\n",
       "         0.82827175],\n",
       "       [ 0.13955928,  0.12330879,  0.767207  ,  0.73767596,  0.719442  ,\n",
       "        -2.4871929 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rates=torch.mean(torch.stack(intensity_matrices,dim=0),dim=0)[0].numpy() # Get the average predicted intensity matrix\n",
    "mean_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Paths during Evaluation</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.662 ± 0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.285 ± 0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.172 ± 0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>0.119 ± 0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.115 ± 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.235 ± 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.882 ± 0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Paths during Evaluation           RMSE\n",
       "0                          1  0.662 ± 0.049\n",
       "1                         30  0.285 ± 0.066\n",
       "2                        100  0.172 ± 0.028\n",
       "3                        300  0.119 ± 0.018\n",
       "4                        500  0.115 ± 0.017\n",
       "5                       1000  0.235 ± 0.019\n",
       "6                       5000  0.882 ± 0.001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "means = {n_paths: torch.tensor(losses).mean().item() for n_paths, losses in result.items()}\n",
    "stds = {n_paths: torch.tensor(losses).std().item() for n_paths, losses in result.items()}\n",
    "\n",
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        \"# Paths during Evaluation\": list(means.keys()),\n",
    "        \"RMSE\": [f\"{mean:.3f} ± {std:.3f}\" for mean, std in zip(means.values(), stds.values())],\n",
    "    }\n",
    ")\n",
    "\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
